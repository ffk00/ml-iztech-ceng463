{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYs1yOURJgTv"
      },
      "source": [
        "# CENG 463 HW 1– Water Resource Risk Classification\n",
        "**Start Date:**  \n",
        "**Due Date:** Month Dayth, 2026\n",
        "\n",
        "## Dataset Overview\n",
        "The dataset utilized in this assignment originates from the World Resources Institute (WRI) – Aqueduct Water Risk Atlas. It provides country-level indicators describing key hydrological and environmental factors, which are listed in the table below. The objective is to classify each country into a Water Resource Risk Category (0-4) using these indicators. Students are also expected to create two derived features — Composite Water Stress Index (CWSI) and Seasonal–Flood Interaction (SFI).\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| gid_0 | Country Code |\n",
        "| bws_score | Baseline Water Stress |\n",
        "| gtd_score | Groundwater Depletion |\n",
        "| drr_score | Drought Risk |\n",
        "| rfr_score | River Flood Risk |\n",
        "| sev_score | Seasonal Variability |\n",
        "| w_awr_def_tot_cat | Target: Water Risk Category (0-4) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJJc9KioJgWI"
      },
      "source": [
        "## 1. Feature Engineering (35 pts)\n",
        "Students are expected to create two new features based on the existing indicators:\n",
        "\n",
        "1. **Composite Water Stress Index (CWSI):**\n",
        "   CWSI combines baseline water stress, groundwater depletion, and drought risk.\n",
        "   Formula: CWSI = 0.5 × bws_score + 0.3 × gtd_score + 0.2 × drr_score\n",
        "\n",
        "2. **Seasonal–Flood Interaction (SFI):**\n",
        "   SFI represents interaction between seasonal variability and river flood risk.\n",
        "   Formula: SFI = sev_score × rfr_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create CWSI and SFI features\n",
        "# df['CWSI'] = ...\n",
        "# df['SFI'] = ...\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#load the dataset\n",
        "df=pd.read_csv(\"water_risk_dataset.csv\")\n",
        "\n",
        "#new features, cwsi and sfi\n",
        "df['CWSI'] =  0.5 * df['bws_score'] + 0.3 * df['gtd_score'] + 0.2 * df['drr_score']\n",
        "df['SFI'] = df['sev_score'] * df['rfr_score']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auuRhydMJgYg"
      },
      "source": [
        "## 2. Model Training & Evaluation (40 pts)\n",
        "Train five classification models: Random Forest, SVM, KNN, Gaussian Naive Bayes, Logistic Regression.\n",
        "\n",
        "*Hint: Use scaled data for SVM, KNN, Logistic Regression.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data splitted into train and test\n"
          ]
        }
      ],
      "source": [
        "# TODO: Split data into features X and target y\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#we drop gid and target columns from the features, because training with gid might cause to overfit and training with the target columns is basically cheating\n",
        "X = df.drop(columns=['gid_0', 'w_awr_def_tot_cat'])\n",
        "y = df['w_awr_def_tot_cat']\n",
        "\n",
        "#cross validation, %80 training %20 test\n",
        "train_X,test_X,train_y,test_y=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "print(\"data splitted into train and test\")\n",
        "\n",
        "#scaled data for SVM, KNN, logistic regression\n",
        "scaler = StandardScaler()\n",
        "train_scaled_X = scaler.fit_transform(train_X)\n",
        "test_scaled_X = scaler.transform(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jIEFe653KGE4"
      },
      "outputs": [],
      "source": [
        "# TODO: Train models and evaluate accuracy\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# random forest (uses unscaled data)\n",
        "rf = RandomForestClassifier(random_state=1923)\n",
        "rf.fit(train_X, train_y)\n",
        "rf_acc = accuracy_score(test_y, rf.predict(test_X))\n",
        "\n",
        "# gaussian naivebayes (uses unscaled data)\n",
        "nb = GaussianNB()\n",
        "nb.fit(train_X, train_y)\n",
        "nb_acc = accuracy_score(test_y, nb.predict(test_X))\n",
        "\n",
        "# SVM (uses scaled data)\n",
        "svm = SVC(random_state=1923)\n",
        "svm.fit(train_scaled_X, train_y)\n",
        "svm_acc = accuracy_score(test_y, svm.predict(test_scaled_X))\n",
        "\n",
        "# KNN (uses scaled data)\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_scaled_X, train_y)\n",
        "knn_acc = accuracy_score(test_y, knn.predict(test_scaled_X))\n",
        "\n",
        "# logistic regression (uses scaled data)\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr.fit(train_scaled_X, train_y)\n",
        "lr_acc = accuracy_score(test_y, lr.predict(test_scaled_X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Model Evaluation:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.914380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gaussian NB</td>\n",
              "      <td>0.609221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.756312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.811196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.687157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Accuracy\n",
              "0        Random Forest  0.914380\n",
              "1          Gaussian NB  0.609221\n",
              "2                  SVM  0.756312\n",
              "3                  KNN  0.811196\n",
              "4  Logistic Regression  0.687157"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO: Prepare evaluation table\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Random Forest', 'Gaussian NB', 'SVM', 'KNN', 'Logistic Regression'],\n",
        "    'Accuracy': [rf_acc, nb_acc, svm_acc, knn_acc, lr_acc]\n",
        "})\n",
        "print(\"Baseline Model Evaluation:\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlCs3MIXJgdI"
      },
      "source": [
        "## 3. Hyperparameter Optimization (20 pts)\n",
        "Tune each model using GridSearchCV with 5-fold CV.\n",
        "Compare baseline and tuned results and report improvements.\n",
        "Identify the model with highest tuned performance.\n",
        "\n",
        "Hint: Use accuracy as scoring metric. Add classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WcGBEmL7KN7Q"
      },
      "outputs": [],
      "source": [
        "# TODO: Define parameter grids for each model\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "param_grids = {\n",
        "    \"Random Forest\": {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5]\n",
        "    },\n",
        "    \"Gaussian NB\": {\n",
        "        'var_smoothing': [1e-9, 1e-8]\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf']\n",
        "    },\n",
        "    \"KNN\": {\n",
        "        'n_neighbors': [3, 5, 7],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'solver': ['lbfgs']\n",
        "    }\n",
        "}\n",
        "\n",
        "#for easier access stored models in dict\n",
        "models_map = {\n",
        "    \"Random Forest\": rf,\n",
        "    \"Gaussian NB\": nb,\n",
        "    \"SVM\": svm,\n",
        "    \"KNN\": knn,\n",
        "    \"Logistic Regression\": lr\n",
        "}\n",
        "\n",
        "tuned_results = {}\n",
        "best_estimators = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Grid Search (this may take a moment)...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest - Best Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100} | Tuned Acc: 0.9144\n",
            "Gaussian NB - Best Params: {'var_smoothing': 1e-09} | Tuned Acc: 0.6092\n",
            "SVM - Best Params: {'C': 10, 'kernel': 'rbf'} | Tuned Acc: 0.7816\n",
            "KNN - Best Params: {'n_neighbors': 3, 'weights': 'distance'} | Tuned Acc: 0.8836\n",
            "Logistic Regression - Best Params: {'C': 1, 'solver': 'lbfgs'} | Tuned Acc: 0.6872\n",
            "\n",
            "Hyperparameter Tuning Comparison:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>Tuned</th>\n",
              "      <th>Improvement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.914380</td>\n",
              "      <td>0.914380</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gaussian NB</td>\n",
              "      <td>0.609221</td>\n",
              "      <td>0.609221</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.756312</td>\n",
              "      <td>0.781559</td>\n",
              "      <td>0.025247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.811196</td>\n",
              "      <td>0.883644</td>\n",
              "      <td>0.072448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.687157</td>\n",
              "      <td>0.687157</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Baseline     Tuned  Improvement\n",
              "0        Random Forest  0.914380  0.914380     0.000000\n",
              "1          Gaussian NB  0.609221  0.609221     0.000000\n",
              "2                  SVM  0.756312  0.781559     0.025247\n",
              "3                  KNN  0.811196  0.883644     0.072448\n",
              "4  Logistic Regression  0.687157  0.687157     0.000000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Performing Model: Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.97      0.96       156\n",
            "         1.0       0.88      0.92      0.90       165\n",
            "         2.0       0.92      0.81      0.86       171\n",
            "         3.0       0.88      0.91      0.89       194\n",
            "         4.0       0.95      0.95      0.95       225\n",
            "\n",
            "    accuracy                           0.91       911\n",
            "   macro avg       0.91      0.91      0.91       911\n",
            "weighted avg       0.91      0.91      0.91       911\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO: Perform GridSearchCV and compare results\n",
        "\n",
        "print(\"Starting Grid Search (this may take a moment)...\")\n",
        "#performing gridsearchcv\n",
        "#for loop is a good idea for this\n",
        "for name, model in models_map.items():\n",
        "    #selecting the data for each model(scaled or unscaled)\n",
        "    if name in [\"SVM\", \"KNN\", \"Logistic Regression\"]:\n",
        "        tune_X = train_scaled_X\n",
        "        val_X = test_scaled_X\n",
        "    else:\n",
        "        tune_X = train_X\n",
        "        val_X = test_X\n",
        "        \n",
        "    #run Grid Search\n",
        "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    grid.fit(tune_X, train_y)\n",
        "    \n",
        "    #save best model\n",
        "    best_model = grid.best_estimator_\n",
        "    best_estimators[name] = best_model\n",
        "    \n",
        "    #score on test set\n",
        "    acc = accuracy_score(test_y, best_model.predict(val_X))\n",
        "    tuned_results[name] = acc\n",
        "    \n",
        "    print(f\"{name} - Best Params: {grid.best_params_} | Tuned Acc: {acc:.4f}\")\n",
        "\n",
        "#compare baseline and tuned\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': results_df['Model'],\n",
        "    'Baseline': results_df['Accuracy'],\n",
        "    'Tuned': [tuned_results[m] for m in results_df['Model']]\n",
        "})\n",
        "comparison_df['Improvement'] = comparison_df['Tuned'] - comparison_df['Baseline']\n",
        "print(\"\\nHyperparameter Tuning Comparison:\")\n",
        "display(comparison_df)\n",
        "\n",
        "#identify best model\n",
        "best_model_name = comparison_df.loc[comparison_df['Tuned'].idxmax()]['Model']\n",
        "print(f\"\\nBest Performing Model: {best_model_name}\")\n",
        "\n",
        "#classification report for the best model\n",
        "final_model = best_estimators[best_model_name]\n",
        "if best_model_name in [\"SVM\", \"KNN\", \"Logistic Regression\"]:\n",
        "    final_preds = final_model.predict(test_scaled_X)\n",
        "else:\n",
        "    final_preds = final_model.predict(test_X)\n",
        "\n",
        "print(classification_report(test_y, final_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPdWaMf3Jghw"
      },
      "source": [
        "## 4. Feature Importance Analysis (5 pts)\n",
        "Choose one model and analyze feature importance. Present most influential features in a table and bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kLRwzRy9KjJg"
      },
      "outputs": [],
      "source": [
        "# TODO: Select your best model (e.g., Random Forest)\n",
        "# TODO: Train the model on the training data if not already trained\n",
        "# TODO: Calculate feature importances\n",
        "# TODO: Create a table of features sorted by importance\n",
        "# TODO: Plot a bar chart of feature importances\n",
        "# TODO: Optional: Comment on top 3-5 most influential features"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
